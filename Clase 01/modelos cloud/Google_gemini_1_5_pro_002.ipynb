{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K3cSV6cu1ts0"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-aiplatform\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "C7fAcW8n2A4J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, SafetySetting"
      ],
      "metadata": {
        "id": "XwZYL2F-2Uv3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Permisos en cuenta de servicio \"Usuario de Vertex AI\"\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/content/ci-data-json.json\""
      ],
      "metadata": {
        "id": "JnxX54vi2hzp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración para la generación de contenido\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 8192, # Número máximo de tokens en la respuesta\n",
        "    \"temperature\": 1, # Control de aleatoriedad: 0.7 balancea creatividad y consistencia\n",
        "    \"top_p\": 0.95, # Método de muestreo para limitar opciones de mayor probabilidad hasta que la suma de sus probabilidades de 95%\n",
        "}"
      ],
      "metadata": {
        "id": "nfg3a7aM4vZ7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE # Bloquea contenido de odio moderado\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH # Bloquea contenido altamente peligroso\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH # Bloquea contenido explícito alto\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH # Bloquea contenido de acoso alto\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "gM6o2JtH4hjb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función principal para generar contenido con Vertex AI\n",
        "\n",
        "def generate(genprompt):\n",
        "    # Inicializa Vertex AI especificando el proyecto y la ubicación\n",
        "    vertexai.init(project=\"ci-sandbox-data\", location=\"us-west4\")\n",
        "    # Elegeimos el modelo generativo Gemini 1.5 Pro\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.5-pro-002\",\n",
        "    )\n",
        "    responses = model.generate_content(\n",
        "        genprompt, # Lista con preguntas o instrucciones\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    for response in responses:\n",
        "        print(response.text, end=\"\")"
      ],
      "metadata": {
        "id": "wPaozXj34suN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate([\"\"\"Cual es la capital de peru\"\"\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8oUttd27Cry",
        "outputId": "de08881d-c5dd-4e71-9eb4-72880ffff1fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La capital de Perú es Lima.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xoOpxDSr72-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}