{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "959YRfTqWTts"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai langchain langchain-community langchain-core\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "HEOkrObwYZMy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI #Clase base para interactuar con OpenAI (ver ant deprecado from langchain.llms import OpenAI)\n",
        "from langchain.chains import LLMChain #Clase base para crear cadenas\n",
        "from langchain.prompts import PromptTemplate #se utiliza para definir plantillas de prompts reutilizables, con variables dinámicas\n",
        "from langchain.prompts import ChatPromptTemplate #clase diseñada para trabajar específicamente con modelos de chat en modo de conversación."
      ],
      "metadata": {
        "id": "nByzseT6YfZX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos la api\n",
        "with open(\"/content/api_key.txt\") as archivo:\n",
        "  apikey = archivo.read()\n",
        "os.environ[\"OPENAI_API_KEY\"] = apikey"
      ],
      "metadata": {
        "id": "EuA9zi3nZURw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3BWCl6PLseJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de cadena de texto\n",
        "\n",
        "- Modelos antiguos Estos modelos más antiguos aceptan una cadena de texto como entrada y devuelven una cadena de texto como salida\n",
        "- Modelos con capacidad de conversación (\"Chat\"): Estos modelos avanzados son diseñados específicamente para interacciones conversacionales"
      ],
      "metadata": {
        "id": "K8-ivsZ-m2eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a hacer una prueba mediante OpenAI usando un modelo antigu modo no conversacional soporte gpt-3.5-turbo-instruct\n",
        "\n",
        "llm = OpenAI(temperature=0.5, model=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "response = llm.invoke(\"¿Cual es la capital de Peru?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaR1Mf28aUli",
        "outputId": "c0919a40-8a3a-432e-f877-d5e8a018f265"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "La capital de Perú es Lima.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "m9dSYvaAsYFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PromptTemplate\n",
        "\n",
        "Diseñado para crear prompts dinámicos con variables, generalmente para tareas no conversacionales."
      ],
      "metadata": {
        "id": "VIjEhFtfryVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Template\n",
        "prompt_template =PromptTemplate.from_template(\"Describe el siguiente producto de una forma convincente y breve {product_name}\")\n",
        "\n",
        "#instancia\n",
        "llm = OpenAI(temperature=0.5)\n",
        "\n",
        "#cadena\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "#ejecutamos\n",
        "input = {'product_name':'Botella de agua ecologica'}\n",
        "print(chain.run(input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFWP--2kn8Rf",
        "outputId": "b7ecccb3-4f0b-498e-f867-93846818316c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "La botella de agua ecológica es la opción perfecta para aquellos que buscan una alternativa sostenible y amigable con el medio ambiente. Fabricada con materiales reciclables y biodegradables, esta botella te permite hidratarte de forma responsable y sin generar residuos dañinos para nuestro planeta. Su diseño moderno y funcional la convierte en un accesorio imprescindible para llevar contigo a todas partes, ya sea al trabajo, al gimnasio o a tus aventuras al aire libre. ¡Haz un cambio positivo en el mundo mientras te mantienes hidratado con la botella de agua ecológica!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "F2wS3eJRsaJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatPromptTemplate\n",
        "Enfocado en la creación de prompts para modelos en formato de chat, como GPT-4 en modo conversacional."
      ],
      "metadata": {
        "id": "ecdSpa6lsGv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "# Crear las plantillas de mensajes\n",
        "system_message = SystemMessagePromptTemplate.from_template(\n",
        "    \"Eres un asistente que genera una descripción de un producto de forma convincente y breve.\"\n",
        ")\n",
        "human_message = HumanMessagePromptTemplate.from_template(\"{product_name}\")\n",
        "\n",
        "# Crear el prompt de chat\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
        "\n",
        "# Instanciar el modelo de chat\n",
        "llm = ChatOpenAI(temperature=0.5)\n",
        "\n",
        "# Crear la cadena\n",
        "chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
        "\n",
        "# Ejecutar la cadena\n",
        "input_data = {'product_name': 'Botella de agua ecológica'}\n",
        "print(chain.run(input_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfdX0a3MqoKt",
        "outputId": "258f4bad-6c27-4bf3-ff63-de2c98a38c9c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Lleva contigo esta botella de agua ecológica y ayuda a reducir el uso de plástico de un solo uso! Fabricada con materiales reciclables y reutilizables, esta botella es perfecta para mantener tu hidratación en todo momento. Su diseño moderno y funcional la convierte en el complemento ideal para tu estilo de vida sostenible. ¡Di no al plástico y sí a esta botella de agua ecológica!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cadenas de secuencia simple"
      ],
      "metadata": {
        "id": "p4Jm9QwktGEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimpleSequentialChain"
      ],
      "metadata": {
        "id": "9dJB3-vExMvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.5)\n",
        "#cadena 01\n",
        "first_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "Indica si el texto denota una emocion en una sola palabra (positiva o Negativa): {mensaje}\"\"\")\n",
        "chain_one = LLMChain(llm=llm, prompt=first_template)\n",
        "\n",
        "#cadena 02\n",
        "second_template =  ChatPromptTemplate.from_template(\"\"\"\n",
        "Envia un mensaje de agradecimiento o Disculpa si el resultado es positivo o Negativo:  {emocion}\n",
        "\"\"\")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_template)\n",
        "\n",
        "#Secuencia lineal\n",
        "cadena_lineal = SimpleSequentialChain(chains=[chain_one, chain_two])\n",
        "resultado = cadena_lineal.run(\"Su producto se malogro al dia siguiente\")\n",
        "\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdcYQsFGtEYL",
        "outputId": "8eb55378-cada-45d1-fc91-3ee2c6750d34"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disculpa por el resultado negativo, seguiré trabajando para mejorar y espero poder brindarte un mejor servicio en el futuro. ¡Gracias por tu comprensión!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SequentialChain"
      ],
      "metadata": {
        "id": "HUEF37rNxO1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.5)\n",
        "# cadena 01 | input: reseña | output: spanish_rev\n",
        "one_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "Traducir la siguiente reseña en español {review}\n",
        "\"\"\")\n",
        "chain_one = LLMChain(llm=llm, prompt=one_template, output_key=\"spanish_rev\")\n",
        "\n",
        "# Cadena 02 | input spanish_rev | output resumen\n",
        "two_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "resume la siguiente reseña en una frase {spanish_rev}\n",
        "\"\"\")\n",
        "chain_two = LLMChain(llm=llm, prompt=two_template, output_key=\"resumen\")\n",
        "\n",
        "#cadena 03 | input review | output lenguaje\n",
        "three_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "En que idioma se encuentra la siguiente reseña {review}\n",
        "\"\"\")\n",
        "chain_three = LLMChain(llm=llm, prompt=three_template, output_key=\"lenguaje\")\n",
        "\n",
        "#cadena 04 | input resumen,lenguaje | output mensaje_seg\n",
        "four_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "Escribe una respuesta de seguimiento a el siguiente resumen en el idioma especificado {resumen}, idioma: {lenguaje}\n",
        "\"\"\")\n",
        "chain_four = LLMChain(llm=llm, prompt=four_template, output_key=\"mensaje_seg\")\n",
        "\n",
        "#flujo de cadena\n",
        "\n",
        "cadena_secuencial = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
        "    input_variables=[\"review\"],\n",
        "    output_variables=[\"spanish_rev\", \"resumen\", \"lenguaje\", \"mensaje_seg\"]\n",
        ")"
      ],
      "metadata": {
        "id": "SZHTOehIc39T"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"\"\"For all their convenience, Bluetooth headphones and earbuds have fundamental problems.\n",
        "            Take their batteries (please). They're only fully rechargeable 300–500 times,\n",
        "            which means that after just two or three years of moderate-to-heavy use,\n",
        "            most people toss their depleted wireless ear-fi in a drawer and buy a new pair.\"\"\""
      ],
      "metadata": {
        "id": "uDJP9f1wvfBc"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cadena_secuencial.invoke(review)"
      ],
      "metadata": {
        "id": "SpbNQLfgzVWP"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Traduccion: \"+ result['spanish_rev'] +\"\\n\\n\"+\n",
        "      \"Resumen: \"+ result['resumen'] +\"\\n\\n\"+\n",
        "      \"Idioma: \"+ result['lenguaje'] +\"\\n\\n\"+\n",
        "      \"Respuesta: \"+ result['mensaje_seg']\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvvioKsczY3X",
        "outputId": "d5be5269-887a-4f41-cb52-14b48d08043e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traduccion: A pesar de toda su conveniencia, los auriculares y audífonos Bluetooth tienen problemas fundamentales. Tome sus baterías (por favor). Solo se pueden recargar completamente de 300 a 500 veces, lo que significa que después de solo dos o tres años de uso moderado a intenso, la mayoría de las personas tiran sus auriculares inalámbricos agotados en un cajón y compran un par nuevo.\n",
            "\n",
            "Resumen: Los auriculares y audífonos Bluetooth tienen problemas de durabilidad debido a la limitada vida útil de sus baterías.\n",
            "\n",
            "Idioma: La reseña está en inglés.\n",
            "\n",
            "Respuesta: Thank you for bringing up the issue of durability with Bluetooth headphones and earphones. It is true that the limited lifespan of their batteries can be a concern for many users. Manufacturers are constantly working on improving battery technology to address this issue. In the meantime, it's important for consumers to properly care for their devices and follow recommended charging practices to maximize the lifespan of their batteries. Hopefully, we will see advancements in battery technology that will provide longer-lasting and more durable Bluetooth headphones and earphones in the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cadena Condicional"
      ],
      "metadata": {
        "id": "CjZ3QoSP11Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.5)\n",
        "\n",
        "rw=\"Tengo un problema con los audifonos que me vendieron, no funcionan desde el primer dia\"\n",
        "\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"analiza el sentimiento de la siguiente reseña\n",
        "    y devuelve el resultado en una sola palabra, positivo o negativo {review}\"\"\"\n",
        "    )\n",
        "\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Genera una respuesta de agradecimiento para la siguiente reseña positiva {review}\"\"\")\n",
        "\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Genera una respuesta de disculpas para la siguiente reseña negativa {review}\"\"\")\n",
        "\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key= \"sentiment\")\n",
        "result_one = chain_one.run({\"review\": rw})\n",
        "\n",
        "#cadena de respuesta condicional\n",
        "\n",
        "if \"positivo\" in result_one.lower():\n",
        "  chain_three = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key= \"response\")\n",
        "elif \"negativo\" in result_one.lower():\n",
        "  chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                     output_key= \"response\")\n",
        "  result_three = chain_three.run({\"review\": rw})\n",
        "\n",
        "  print(result_three)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHBmJ_0EznGk",
        "outputId": "1dbeb2a9-edcd-43ff-8332-0da682b97bc8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lamentamos mucho escuchar que has tenido problemas con los audífonos que adquiriste. Nos disculpamos por cualquier inconveniente que esto te haya causado. Por favor, contáctanos para que podamos resolver este problema de la mejor manera posible y encontrar una solución que te satisfaga. Tu satisfacción es nuestra prioridad y estamos comprometidos en brindarte el mejor servicio posible. ¡Gracias por tu comprensión!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cadena Condicional como funcion"
      ],
      "metadata": {
        "id": "UJtJpj5R7Nt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_chain(review, client):\n",
        "\n",
        "  first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"analiza el sentimiento de la siguiente reseña\n",
        "    y devuelve el resultado en una sola palabra, positivo o negativo {review}\"\"\"\n",
        "    )\n",
        "\n",
        "  second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Genera una respuesta de agradecimiento para {client} en formato de correo para la siguiente reseña positiva {review}\"\"\")\n",
        "\n",
        "  third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Genera una respuesta de disculpas para {client} en formato de correo para la siguiente reseña negativa {review}\"\"\")\n",
        "\n",
        "  #cadena 1 analisis de sentimiento\n",
        "  chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key= \"sentiment\")\n",
        "  result_one = chain_one.run({\"review\": rw})\n",
        "\n",
        "  #cadena 3 condicional\n",
        "  if \"positivo\" in result_one.lower():\n",
        "    chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key= \"response\")\n",
        "  elif \"negativo\" in result_one.lower():\n",
        "    chain_two = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                     output_key= \"response\")\n",
        "    result_chain = chain_two.run({\"review\": rw, \"client\": client})\n",
        "  return result_chain"
      ],
      "metadata": {
        "id": "JywzC1rv3ghL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"\"\"For all their convenience, Bluetooth headphones and earbuds have fundamental problems.\n",
        "            Take their batteries (please). They're only fully rechargeable 300–500 times,\n",
        "            which means that after just two or three years of moderate-to-heavy use,\n",
        "            most people toss their depleted wireless ear-fi in a drawer and buy a new pair.\"\"\"\n",
        "client= \"Javier Orihuela\"\n",
        "\n",
        "result = main_chain(review,client)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaCK3e4p4YmH",
        "outputId": "89afbb05-f1fe-4d74-a560-62c889029048"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimado Javier Orihuela,\n",
            "\n",
            "Lamentamos profundamente la experiencia negativa que has tenido con los audífonos que adquiriste en nuestra tienda. Nos disculpamos sinceramente por cualquier inconveniente que esto te haya causado.\n",
            "\n",
            "Queremos asegurarte que la satisfacción de nuestros clientes es nuestra prioridad y nos tomamos muy en serio cualquier problema que pueda surgir con nuestros productos. Por favor, háznoslo saber y estaremos encantados de ofrecerte una solución inmediata.\n",
            "\n",
            "Por favor, acércate a nuestra tienda con los audífonos y el comprobante de compra para que podamos evaluar la situación y encontrar la mejor manera de resolver este inconveniente.\n",
            "\n",
            "Una vez más, te pedimos disculpas por los inconvenientes causados y agradecemos tu comprensión y paciencia en este asunto.\n",
            "\n",
            "Atentamente,\n",
            "[Nombre de la empresa]\n"
          ]
        }
      ]
    }
  ]
}